= Background
What is *AI*?\
There are many interpretations of *Artificial Intelligence*, which depends on the goal of the model. Are we try to make machines that:
- Behave like humans
- Act like humans
- Think rationally
- Act rationally
These are just some of the general interpretation of what an AI should be. The perspectives above highlights how some goals when making AI are results based or method based.

== Rational Decisions
We use the term *Rational* in a very specific way. *Rationality* Maximally achieve a predetermined goal. We express this in terms of utility of the outcome, how much is the outcome worth. With added certainty, we are technically maximizing the *Expected Utility*.\

== Designing Rational Agents
An *Agent* is an entity that perceives and acts. A *Rational Agent* selects actions that maximize its (expected) utility based on its environment. An abstract of this is that the agent is in an environment, where it perceives the actions of its surroundings and takes actions accordingly.\

- Skill-based Perspective
  - Can the model perform tasks
- Embodiment Perspective
  - Be able to take action in the world. Build the body and go from there
- Psychometrics Perspective
  - Instead of Measuring specific abilities, measure it on a broad range of tasks
- Human-Compatible Perspective
  - Maximize human utility. But since human utility is not well defined, it has inherent uncertainty
  
=== Reflex Agents
The simplest type of agent is the reflex agent, which chooses action based on current percept. It could have some memory of past events but doesn't take into account future details.

=== Planning Agents
These agents take into account the future consequences of their actions based on a formulated goal.


